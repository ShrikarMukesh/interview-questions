
---

## ğŸ”¹ 1. What is Apache Kafka, and how is it different from traditional message brokers?

**Apache Kafka** is a **distributed event streaming platform** designed for high-throughput, low-latency data pipelines and real-time processing.

âœ… Differences from RabbitMQ / ActiveMQ (traditional message brokers):

* **Architecture**:

    * Kafka is distributed, partitioned, and replicated out of the box.
    * Traditional brokers are often centralized (with some clustering support).
* **Throughput**:

    * Kafka can handle **millions of events/sec** with low latency.
    * RabbitMQ/ActiveMQ are better suited for smaller workloads.
* **Storage model**:

    * Kafka stores messages on disk (append-only log) â†’ can **replay** old messages.
    * Traditional brokers typically remove messages once consumed.
* **Consumer model**:

    * Kafka consumers pull messages at their own pace.
    * RabbitMQ pushes messages to consumers.
* **Use cases**:

    * Kafka â†’ event streaming, analytics, log aggregation, microservices communication.
    * RabbitMQ â†’ task queues, request/reply patterns, transactional workflows.

ğŸ‘‰ Interview tip: Emphasize **Kafka = scalable, replayable, distributed streaming system**, not just a queue.

---

## ğŸ”¹ 2. Explain Kafkaâ€™s Core Components

* **Topic** â†’ Named stream of records (like a table in DB). Example: `payments.initiated`.
* **Partition** â†’ A topic is divided into partitions for **parallelism & scalability**. Each partition is an **append-only log**.
* **Broker** â†’ A Kafka server that stores topic partitions. A Kafka cluster = multiple brokers.
* **Consumer Group** â†’ A group of consumers working together to consume partitions of a topic.

    * Each partition is consumed by **exactly one consumer in the group** (ensures load balancing).
    * Multiple groups can consume the same topic independently.

ğŸ‘‰ Example: If a topic has 6 partitions and a consumer group has 3 consumers, each consumer will handle 2 partitions.

---

## ğŸ”¹ 3. How does Kafka ensure scalability and fault tolerance?

**Scalability**

* Topics split into **partitions** â†’ processed in parallel by multiple consumers.
* You can add brokers to the cluster â†’ Kafka automatically balances partitions.

**Fault Tolerance**

* Each partition has a **replication factor** (e.g., 3).
* One broker is the **leader**, others are **followers**.
* If leader crashes â†’ a follower is elected as new leader.
* Data is considered durable when written to all **in-sync replicas (ISR)**.

---

## ğŸ”¹ 4. What is the role of Zookeeper in Kafka? (Pre-Kafka 3.x)

* Maintains **metadata** about brokers, topics, and partitions.
* Handles **leader election** for partitions.
* Keeps track of **broker membership** (who is alive).
* Stores **ACLs & configurations**.

âš¡ Note: Since **Kafka 3.0**, Zookeeper is being phased out, replaced by **KRaft (Kafka Raft Metadata mode)** â†’ Kafka manages metadata internally without Zookeeper.

ğŸ‘‰ In interviews, mention both:

* â€œHistorically Kafka used Zookeeper, but new versions use KRaft for metadata management.â€

---

## ğŸ”¹ 5. Difference between Queue Semantics and Publish-Subscribe Semantics in Kafka

* **Queue Semantics** (like RabbitMQ):

    * Each message is consumed by **only one consumer**.
    * Used for load balancing (tasks split among workers).

* **Publish-Subscribe Semantics** (Kafkaâ€™s strength):

    * A message can be consumed by **multiple consumer groups** independently.
    * Each consumer group gets its own copy of the stream.
    * Example:

        * Analytics service consumes `payments.initiated` for BI reports.
        * Fraud detection service consumes the same topic for anomaly detection.

ğŸ‘‰ Kafka supports both **queue semantics (via consumer groups)** and **pub-sub (via multiple groups on same topic)**.


## ğŸ”¹ 6. What is the difference between Kafka and a database?

* Kafka is not a database â€” itâ€™s a **commit log + event streaming platform**.
* Kafka stores messages temporarily (configurable retention), while DBs store data permanently.
* Kafka supports **replaying messages**, but doesnâ€™t provide SQL-style queries (except via ksqlDB).

---

## ğŸ”¹ 7. How does Kafka handle message ordering?

* Kafka guarantees **ordering within a single partition**.
* Across multiple partitions, ordering is **not guaranteed**.
* To enforce ordering for related events, you must use the **same key** (all messages with same key go to same partition).

---

## ğŸ”¹ 8. What is the difference between Kafka topics and partitions?

* **Topic** = logical name (like a category).
* **Partition** = physical logs where data is stored.
* A topic may have multiple partitions â†’ enables parallelism.

---

## ğŸ”¹ 9. What is the difference between Kafka and traditional file storage (e.g., logs on disk)?

* Traditional logs are local, not distributed.
* Kafka logs are **distributed, replicated, durable, and consumable in parallel**.

---

## ğŸ”¹ 10. What is a Kafka offset?

* Offset = sequential ID for each message in a partition.
* Consumers use offsets to track progress.
* Kafka does not delete messages after consumption â†’ offset allows **reprocessing** if needed.

---

## ğŸ”¹ 11. What are Kafka retention policies?

* Kafka retains data for a **configured time** (e.g., 7 days) or until log reaches a **configured size**.
* Types:

    * **Delete policy** â†’ removes old data after retention time.
    * **Compact policy** â†’ keeps only the latest message for each key (good for changelog topics).

---

## ğŸ”¹ 12. How does Kafka handle consumer failure?

* If a consumer crashes, Kafka rebalances partitions among the remaining consumers in the group.
* The new consumer picks up from the **last committed offset**.

---

## ğŸ”¹ 13. What is Kafkaâ€™s pull model vs push model?

* Kafka uses a **pull model** (consumers poll for messages).
* Traditional brokers (RabbitMQ) use **push model**.
* Pull model gives consumers **backpressure control** (consume at their own pace).

---

## ğŸ”¹ 14. What happens if a Kafka broker goes down?

* If the broker was **a follower**, nothing happens.
* If it was a **leader**:

    * Kafka elects a new leader from the **in-sync replicas (ISR)**.
    * Clients automatically redirect to the new leader.

---

## ğŸ”¹ 15. How does Kafka achieve high throughput?

* Sequential disk writes (append-only logs).
* Page cache + zero-copy transfer (via `sendfile`).
* Batching of messages.
* Compression (snappy, gzip, lz4).
* Horizontal scalability via partitions.

---

## ğŸ”¹ 16. Difference between Kafka and Kafka Streams?

* **Kafka** = message broker (pub-sub + storage).
* **Kafka Streams** = Java library for **real-time stream processing** (aggregations, joins, windowing).

---

## ğŸ”¹ 17. What is a replication factor in Kafka?

* Number of copies of a partition across brokers.
* Example: replication factor = 3 â†’ one leader + two followers.
* Ensures **fault tolerance**.

---

## ğŸ”¹ 18. What is the difference between In-Sync Replicas (ISR) and Out-of-Sync Replicas (OSR)?

* **ISR** = replicas fully caught up with the leader.
* **OSR** = replicas lagging behind.
* Kafka only acknowledges writes once committed to ISR (for durability).

---

## ğŸ”¹ 19. What is Kafkaâ€™s exactly-once semantics?

* Kafka provides **exactly-once** with:

    * **Idempotent producer** (no duplicate writes).
    * **Transactional producer/consumer** (atomic send + commit).
    * Careful integration with DB (outbox pattern).

---

## ğŸ”¹ 20. Difference between Kafka and Kinesis (AWS)?

* Kafka = open-source, self-managed, supports on-prem & cloud.
* Kinesis = AWS-managed service, limited ecosystem.
* Kafka supports **replay, compaction, high customizability**, while Kinesis is simpler but less flexible.

---

ğŸ”¥ Great â€” letâ€™s move from **basics** to the **Producer & Consumer level questions** 

---

# ğŸŸ¢ Kafka Producer Interview Questions

### 1. What is the role of a Kafka Producer?

* A producer **publishes messages to Kafka topics**.
* It decides **which partition** a message goes to.
* Supports **asynchronous + synchronous send**.

---

### 2. How does a producer decide the partition for a message?

* **If a key is provided** â†’ partition = `hash(key) % numPartitions`.
* **If no key** â†’ round-robin across partitions.
* Custom partitioners can also be implemented.

---

### 3. What are Kafka Producer Acknowledgment (`acks`) settings?

* `acks=0` â†’ Producer does **not wait** for acknowledgment. (fast, but risk of data loss).
* `acks=1` â†’ Producer waits for **leader only**. (balanced tradeoff).
* `acks=all` â†’ Producer waits for **all in-sync replicas**. (safest).

---

### 4. What is idempotent producer in Kafka?

* Ensures **no duplicate messages** even during retries.
* Enabled with `enable.idempotence=true`.
* Guarantees **exactly-once delivery** per partition.

---

### 5. How does Kafka Producer handle retries?

* Producer retries sending if a temporary error occurs.
* Configurable with `retries` and `retry.backoff.ms`.
* Combined with idempotence â†’ safe retries.

---

### 6. Difference between `linger.ms` and `batch.size` in producer?

* `linger.ms`: wait time before sending a batch (to accumulate more records).
* `batch.size`: max size of the batch buffer before sending.
* Both improve **throughput** by batching.

---

---

# ğŸ”µ Kafka Consumer Interview Questions

### 1. What is the role of a Kafka Consumer?

* Consumers **subscribe to topics** and **read messages from partitions**.
* They are grouped into **consumer groups** for parallel processing.

---

### 2. What is a Consumer Group?

* A group of consumers sharing a **group.id**.
* Kafka assigns **each partition to exactly one consumer** within a group.
* Ensures **parallelism + load balancing**.

---

### 3. What is consumer rebalancing?

* When a consumer **joins/leaves** a group, Kafka **redistributes partitions** among the active consumers.
* Causes temporary unavailability.
* Handled by **Kafka Coordinator**.

---

### 4. What is offset management in Kafka?

* Each consumer keeps track of **last read offset**.
* Can be committed **automatically** (`enable.auto.commit=true`) or **manually**.
* Stored in Kafka topic `__consumer_offsets`.

---

### 5. Difference between auto offset reset: `earliest` vs `latest`?

* `earliest` â†’ consumer starts from **beginning of the log**.
* `latest` â†’ consumer starts from **latest offset (new messages only)**.

---

### 6. What happens if a consumer crashes?

* If offsets were committed â†’ new consumer continues from **last committed offset**.
* If offsets were not committed â†’ messages may be **reprocessed** (at-least-once).

---

### 7. What is Kafka Consumer Poll mechanism?

* Consumers use `poll()` to fetch messages.
* Must be called **regularly**.
* If poll is not called within `max.poll.interval.ms`, consumer is considered **dead â†’ triggers rebalance**.

---

### 8. What is the difference between at-least-once, at-most-once, and exactly-once delivery in Kafka?

* **At-most-once** â†’ offset committed **before processing** â†’ risk of data loss.
* **At-least-once** â†’ offset committed **after processing** â†’ may cause duplicates.
* **Exactly-once** â†’ handled via **idempotent producer + transactions**.

---

### 9. What is Kafka Partition Assignment Strategy?

* Defines how partitions are assigned among consumers.
* Common strategies:

    * **Range** â†’ partitions divided into ranges.
    * **RoundRobin** â†’ partitions distributed evenly.
    * **Sticky** â†’ minimizes partition movement during rebalance.

---

### 10. How do you improve Kafka Consumer performance?

* Increase **max.poll.records** (fetch more per poll).
* Use **multiple consumers** in group.
* Enable **async processing**.
* Tune **fetch.min.bytes** and **fetch.max.wait.ms** for batching.

---

Awesome ğŸš€ â€” letâ€™s build a **mock interview Q\&A sheet** for a **Spring Boot + Kafka Microservice interview**.
Iâ€™ll structure it like **how an interviewer might ask** â†’ and how **you should ideally answer**.

---

# ğŸ“ Spring Boot + Kafka Mock Interview Q\&A Sheet

---

## ğŸ”¹ Section 1: Kafka Basics

**Q1.** What is Apache Kafka, and how is it different from traditional message brokers?
âœ… **Answer:**
Kafka is a **distributed event streaming platform** for high-throughput, fault-tolerant, real-time data pipelines. Unlike RabbitMQ/ActiveMQ (which are queue-based), Kafka:

* Stores messages on disk (durable).
* Supports **publish-subscribe** + **queue semantics**.
* Provides **scalability** via partitioning.
* Uses **consumer groups** for parallelism.

---

**Q2.** What is a Kafka topic and partition?
âœ… **Answer:**

* A **topic** is a logical stream of records.
* Each topic is split into **partitions** for scalability and parallelism.
* Messages inside partitions are ordered, but Kafka does not guarantee global ordering across partitions.

---

## ğŸ”¹ Section 2: Producers & Consumers

**Q3.** How does Kafka ensure message delivery guarantees?
âœ… **Answer:**

* **At-most-once** â†’ commit offset before processing.
* **At-least-once** â†’ commit after processing (can cause duplicates).
* **Exactly-once** â†’ idempotent producers + transactions + proper offset handling.

---

**Q4.** How does a Kafka producer decide which partition to send a message to?
âœ… **Answer:**

* If a key is provided â†’ `hash(key) % partitionCount`.
* If no key â†’ round-robin.
* We can also use a **custom partitioner**.

---

**Q5.** What is a consumer group and how does it help scalability?
âœ… **Answer:**

* A **consumer group** is a set of consumers sharing a **group.id**.
* Kafka ensures **each partition is consumed by exactly one consumer** within a group.
* Enables **parallelism + load balancing**.

---

## ğŸ”¹ Section 3: Spring Boot + Kafka

**Q6.** How do you produce and consume messages in Spring Boot?
âœ… **Answer:**

* Produce using `KafkaTemplate`.

```java
kafkaTemplate.send("orders", orderId, orderJson);
```

* Consume using `@KafkaListener`.

```java
@KafkaListener(topics = "orders", groupId = "order-service")
public void consume(String msg) { ... }
```

---

**Q7.** How do you handle retries and errors in Spring Kafka?
âœ… **Answer:**

* Use **DefaultErrorHandler** with backoff policy.
* Configure **Dead Letter Topic (DLT)** for failed messages.

```java
@Bean
public DefaultErrorHandler errorHandler(KafkaTemplate<?, ?> template) {
    return new DefaultErrorHandler(
        new DeadLetterPublishingRecoverer(template),
        new FixedBackOff(1000L, 3L)
    );
}
```

---

**Q8.** How do you achieve exactly-once processing in Spring Boot Kafka microservices?
âœ… **Answer:**

* Enable **idempotent producer** (`enable.idempotence=true`).
* Use **Kafka transactions** with Spring `@Transactional`.
* Example: save DB + send Kafka event in the same transaction.

---

## ğŸ”¹ Section 4: Scenario-Based Questions

**Q9.** Suppose you are building an Order microservice with Kafka. How would you design it?
âœ… **Answer (High-level):**

1. **Order Service** â†’ Receives order requests â†’ Publishes to `orders` topic.
2. **Payment Service** â†’ Consumes `orders` â†’ Processes payment â†’ Publishes to `payments`.
3. **Inventory Service** â†’ Consumes `orders` â†’ Updates stock â†’ Publishes to `inventory-updates`.
4. **Error Handling** â†’ Failed messages go to `orders.DLT`.
5. **Exactly-once** â†’ Use idempotent producers + DB transactions.

---

**Q10.** What will happen if one consumer in a group fails?
âœ… **Answer:**

* Kafka will trigger a **rebalance**.
* The partitions assigned to the failed consumer will be redistributed among the remaining consumers.

---

**Q11.** How do you scale Kafka consumers in Spring Boot?
âœ… **Answer:**

* Increase **`concurrency`** in `ConcurrentKafkaListenerContainerFactory`.
* Add more consumers with the same **group.id**.
* Ensure topic partitions â‰¥ number of consumers.

---

**Q12.** How do you secure Kafka in a production Spring Boot microservice?
âœ… **Answer:**

* Use **SASL/SSL** authentication.
* Configure `spring.kafka.security.protocol`, `sasl.mechanism`, and `ssl.*` properties.
* Implement **authorization policies** for producers/consumers.

---

## ğŸ”¹ Section 5: Advanced

**Q13.** What is the difference between Kafka and Kafka Streams?
âœ… **Answer:**

* **Kafka** â†’ Pub-sub messaging backbone.
* **Kafka Streams** â†’ Library for building **real-time processing applications** directly on top of Kafka (filter, map, join, windowing).

---

**Q14.** How do you monitor Kafka consumers in production?
âœ… **Answer:**

* Use **Spring Actuator metrics** (Micrometer + Prometheus + Grafana).
* Monitor lag with **Kafka Exporter** or **Burrow**.
* Key metrics: consumer lag, rebalance frequency, throughput, error count.

---

**Q15.** How do you ensure ordering in Kafka?
âœ… **Answer:**

* Ordering is guaranteed **within a partition**, not across partitions.
* To preserve order â†’ always send related events with the same **key**.

---

# ğŸŸ¢ Spring Boot + Kafka Interview Questions

## 1. How do you configure a Kafka producer in Spring Boot?

* Using `application.yml` or `application.properties`:

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
      properties:
        enable.idempotence: true
```

* Use `KafkaTemplate<String, String>` to send messages.

---

## 2. How do you configure a Kafka consumer in Spring Boot?

```yaml
spring:
  kafka:
    consumer:
      group-id: my-consumer-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
```

* Consume messages with `@KafkaListener`:

```java
@KafkaListener(topics = "orders", groupId = "order-service")
public void consume(String message) {
    System.out.println("Received: " + message);
}
```

---

## 3. How do you handle consumer offset commits in Spring Kafka?

* **Auto commit** (default): not recommended for critical systems.
* **Manual commit**:

```java
@KafkaListener(topics = "orders")
public void consume(ConsumerRecord<String, String> record, Acknowledgment ack) {
    process(record.value());
    ack.acknowledge();  // commit offset manually
}
```

---

## 4. How do you implement retries in Spring Kafka?

* Configure `spring.kafka.listener.retry` or use `SeekToCurrentErrorHandler`.
* Example with exponential backoff:

```java
@Bean
public DefaultErrorHandler errorHandler() {
    FixedBackOff backOff = new FixedBackOff(1000L, 3L); // 3 retries, 1s apart
    return new DefaultErrorHandler(backOff);
}
```

---

## 5. How do you implement Dead Letter Queue (DLT) in Spring Kafka?

* Configure a DLT topic (e.g., `orders.DLT`).
* Spring will publish failed messages automatically:

```java
@Bean
public DeadLetterPublishingRecoverer deadLetterPublishingRecoverer(KafkaTemplate<?, ?> template) {
    return new DeadLetterPublishingRecoverer(template,
        (record, ex) -> new TopicPartition(record.topic() + ".DLT", record.partition()));
}
```

---

## 6. How do you handle exactly-once delivery in Kafka with Spring Boot?

* Enable **idempotent producer** (`enable.idempotence=true`).
* Use **transactions**:

```java
@Bean
public KafkaTemplate<String, String> kafkaTemplate(ProducerFactory<String, String> pf) {
    KafkaTemplate<String, String> template = new KafkaTemplate<>(pf);
    template.setTransactionIdPrefix("tx-");
    return template;
}
```

* Wrap send + DB update inside a transaction:

```java
@Transactional
public void processOrder(Order order) {
    orderRepository.save(order);
    kafkaTemplate.send("orders", order.getId(), order.toString());
}
```

---

## 7. What is the role of `ConcurrentKafkaListenerContainerFactory`?

* Controls **concurrency** of `@KafkaListener`.
* Example:

```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
        ConsumerFactory<String, String> cf) {
    ConcurrentKafkaListenerContainerFactory<String, String> factory =
            new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(cf);
    factory.setConcurrency(3); // parallel consumers
    return factory;
}
```

---

## 8. How do you secure Kafka in Spring Boot?

* Configure **SASL/SSL** properties:

```yaml
spring:
  kafka:
    security:
      protocol: SASL_PLAINTEXT
    properties:
      sasl.mechanism: SCRAM-SHA-512
      sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username="user" password="pass";
```

---

## 9. How do you implement Kafka Streams in Spring Boot?

```java
@Bean
public KStream<String, String> kStream(StreamsBuilder builder) {
    KStream<String, String> stream = builder.stream("orders");
    stream.filter((key, value) -> value.contains("valid"))
          .to("valid-orders");
    return stream;
}
```

---

## 10. What are common error handling strategies in Spring Kafka?

* **Retry + DLQ** (most common).
* **Skip bad messages** (`DefaultErrorHandler` with `setAckAfterHandle(false)`).
* **Stop container on fatal error** (rare, mostly for debugging).

---
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Order Service     â”‚
          â”‚  (Spring Boot REST)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ 1ï¸âƒ£ Publish Order Event
                      â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚       Kafka Topic      â”‚
             â”‚        "orders"        â”‚
             â”‚ (3 partitions, RF=3)   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚                       â”‚
     â–¼               â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Payment Svcâ”‚  â”‚Inventory Svcâ”‚       â”‚ Notification Svcâ”‚
â”‚Consumes   â”‚  â”‚Consumes      â”‚       â”‚ Consumes orders â”‚
â”‚"orders"   â”‚  â”‚"orders"      â”‚       â”‚ "orders" topic  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚               â”‚                        â”‚
â”‚ 2ï¸âƒ£ Publish    â”‚ 3ï¸âƒ£ Publish            â”‚
â–¼               â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "payments" â”‚  â”‚ "inventory-upd"â”‚        â”‚ "emails"     â”‚
â”‚   topic    â”‚  â”‚    topic       â”‚        â”‚   topic      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Dead Letter Topic (DLT)       â”‚
          â”‚  "orders.DLT"                     â”‚
          â”‚  Stores failed/unprocessed events â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
